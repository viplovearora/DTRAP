{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e016ba07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gurobipy import *\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from statistics import mean\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1de6a8ac",
   "metadata": {},
   "source": [
    "Read the data, the csv file can be obtained from https://www.pnas.org/doi/abs/10.1073/pnas.2016238117#supplementary-materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ba085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv('pnas.2016238117.sd04.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9802db5f",
   "metadata": {},
   "source": [
    "Choose the year of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8dcb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2014\n",
    "dat_sub = dat[dat['year']==year]\n",
    "dat_sub = dat_sub.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d5cdc6",
   "metadata": {},
   "source": [
    "Define variables for the problem using the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b518253",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = dat_sub.shape[0]\n",
    "Q = dat_sub['crew_size']\n",
    "Cq = np.log1p(dat_sub.iloc[:,20])\n",
    "gamma = 0.25\n",
    "k = (dat_sub['Prediction'] == 'Positive').sum() * gamma\n",
    "num_samples = 1000\n",
    "# define proportion of trafficking as a random variable\n",
    "s_mean = dat_sub['.pred_1']\n",
    "mar = .1\n",
    "s=np.minimum(np.maximum(np.random.triangular(left=s_mean-mar, mode=s_mean, right=s_mean+mar, size=(num_samples, len(s_mean))),0),1)\n",
    "\n",
    "S1 = [Q*(1-s[j]) for j in range(num_samples)]\n",
    "S2 = [Q*s[j] for j in range(num_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafabd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_rate(x):\n",
    "    xn = x/x.sum()\n",
    "    return xn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fdb728c1",
   "metadata": {},
   "source": [
    "Choose the base TPR and TNR rates (con_base) along with the bias scenario (ca) and compute the TPR and TNR rate for each vessel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4783ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_base=0.5\n",
    "ca = 'hnlp'\n",
    "ytpr, ytnr = [], []\n",
    "con_set = dat_sub[['fishing_hours', 'average_voyage_duration_hours', 'average_loitering_duration_hours']]\n",
    "for h in range(V):\n",
    "    if ca == 'hpi':\n",
    "        ccon = error_rate(con_set.iloc[h,:])\n",
    "        if(ccon.min() < con_base and ccon.max() < con_base):\n",
    "            ytpr.append(con_base)\n",
    "            ytnr.append(con_base)\n",
    "        if(ccon.min() < con_base and ccon.max() > con_base):\n",
    "            ytpr.append(ccon.max())\n",
    "            ytnr.append(con_base)\n",
    "        if(ccon.min() > con_base and ccon.max() > con_base):\n",
    "            ytpr.append(ccon.max())\n",
    "            ytnr.append(ccon.min())\n",
    "    if ca == 'hni':\n",
    "        ccon = error_rate(con_set.iloc[h,:])\n",
    "        if(ccon.min() < con_base and ccon.max() < con_base):\n",
    "            ytpr.append(con_base)\n",
    "            ytnr.append(con_base)\n",
    "        if(ccon.min() < con_base and ccon.max() > con_base):\n",
    "            ytpr.append(con_base)\n",
    "            ytnr.append(ccon.max())\n",
    "        if(ccon.min() > con_base and ccon.max() > con_base):\n",
    "            ytpr.append(ccon.min())\n",
    "            ytnr.append(ccon.max())\n",
    "    if ca == 'hpln':\n",
    "        ccon = error_rate(con_set.iloc[h,:])\n",
    "        if(ccon.min() == 0):\n",
    "            ytpr.append(ccon.max())\n",
    "            ytnr.append(ccon.min() + float(np.random.uniform(0,.1,1)))\n",
    "        else:\n",
    "            ytpr.append(ccon.max())\n",
    "            ytnr.append(ccon.min())\n",
    "    if ca == 'lpi':\n",
    "        ccon = error_rate(con_set.iloc[h,:])\n",
    "        if(ccon.min() < con_base and ccon.max() < con_base):\n",
    "            ytpr.append(con_base)\n",
    "            ytnr.append(ccon.min())\n",
    "        if(ccon.min() < con_base and ccon.max() > con_base):\n",
    "            ytpr.append(con_base)\n",
    "            ytnr.append(ccon.min())\n",
    "        if(ccon.min() > con_base and ccon.max() > con_base):\n",
    "            ytpr.append(con_base)\n",
    "            ytnr.append(con_base)\n",
    "    if ca == 'lni':\n",
    "        ccon = error_rate(con_set.iloc[h,:])\n",
    "        if(ccon.min() < con_base and ccon.max() < con_base):\n",
    "            ytpr.append(ccon.min())\n",
    "            ytnr.append(con_base)\n",
    "        if(ccon.min() < con_base and ccon.max() > con_base):\n",
    "            ytpr.append(ccon.min())\n",
    "            ytnr.append(con_base)\n",
    "        if(ccon.min() > con_base and ccon.max() > con_base):\n",
    "            ytpr.append(con_base)\n",
    "            ytnr.append(con_base)\n",
    "    if ca == 'hnlp':\n",
    "        ccon = error_rate(con_set.iloc[h,:])\n",
    "        if(ccon.min() == 0):\n",
    "            ytnr.append(ccon.max())\n",
    "            ytpr.append(ccon.min() + float(np.random.uniform(0,.1,1)))\n",
    "        else:\n",
    "            ytnr.append(ccon.max())\n",
    "            ytpr.append(ccon.min())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8980d4cf",
   "metadata": {},
   "source": [
    "Compute coefficients for the optimization problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f52222",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytpr, ytnr = np.array(ytpr), np.array(ytnr)\n",
    "coeff2 = [[a*b for a,b in zip(S2[j],ytpr)] for j in range(num_samples)]\n",
    "coeff3 = [[a*b for a,b in zip(S1[j],ytnr)] for j in range(num_samples)]\n",
    "coq = [S1[j]*(1-ytnr)+S2[j]*(1-ytpr) for j in range(num_samples)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "114473d9",
   "metadata": {},
   "source": [
    "Fix RHS for the opimization problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc462e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 10000\n",
    "K = k\n",
    "L = 10000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "483e715a",
   "metadata": {},
   "source": [
    "Formulate DTRAP-SOFTCON for GFW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c45b6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pen = 20        # penalty for constraint violation, see Appendix F\n",
    "m = Model()\n",
    "m.ModelSense = 1  # minimize\n",
    "# Add variables\n",
    "x = m.addVars(V, vtype=GRB.BINARY, name='x')\n",
    "y1 = m.addVar(0, 10000, vtype='C', name='y1')\n",
    "y2 = m.addVar(0, 10000, vtype='C', name='y2')\n",
    "error = m.addVars(num_samples, obj=1.0/num_samples, name='error')\n",
    "# Set constraints\n",
    "m.addConstr(quicksum(Cq.iloc[i]*x[i] for i in range(V)) <= B, name=\"resources\")\n",
    "m.addConstrs((quicksum(coeff2[j][i]*x[i] for i in range(V)) + y1 >= K for j in range(num_samples)), name=\"HT\")\n",
    "m.addConstrs((quicksum(coeff3[j][i]*x[i] for i in range(V)) - y2 <= L for j in range(num_samples)), name=\"NHT\")\n",
    "m.addConstrs((error[j] == quicksum(coq[j].iloc[i]*x[i] for i in range(V)) for j in range(num_samples)), name='error')\n",
    "m.setPWLObj(y1, [-1,0,1], [0,0,pen])\n",
    "m.setPWLObj(y2, [-1,0,1], [0,0,pen])\n",
    "m.update()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77ec9f21",
   "metadata": {},
   "source": [
    "For HNI bias scenario, change the default optimality gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25b786d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if ca == 'hni':\n",
    "\tm.Params.MIPGap = .005"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10cb52e8",
   "metadata": {},
   "source": [
    "Solve the optimization problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d528256",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m.optimize()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4fba3de6",
   "metadata": {},
   "source": [
    "Compute values for the optimal allocation. These are used for creating Table 5 in the manuscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6004dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_monitor = sum([v.X for k,v in x.items()])\n",
    "obj_vals = [v.X for k,v in error.items()]\n",
    "obj = np.mean(obj_vals)\n",
    "k_vals = [quicksum(coeff2[j][i]*x[i] for i in range(V)).getValue() for j in range(num_samples)]\n",
    "l_vals = [quicksum(coeff3[j][i]*x[i] for i in range(V)).getValue() for j in range(num_samples)]\n",
    "sol = [v.X for k,v in x.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361cd2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_monitor)\n",
    "print(round(mean(obj_vals), 2))\n",
    "print(round(sum([Cq.iloc[i]*sol[i] for i in range(V)]), 2))\n",
    "print(round(mean(k_vals), 2))\n",
    "print(round(mean(l_vals), 2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e76484db",
   "metadata": {},
   "source": [
    "Get the allocations using the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3aec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "alloc_ML = np.zeros(V)\n",
    "alloc_ML[np.argsort(s_mean)[-int(num_monitor):]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14309ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(mean(quicksum(coq[j]*alloc_ML).getValue() for j in range(num_samples)), 2))\n",
    "print(round(sum(Cq.iloc[i]*alloc_ML[i] for i in range(V)), 2))\n",
    "print(round(mean([quicksum(coeff2[j][i]*alloc_ML[i] for i in range(V)).getValue() for j in range(num_samples)]), 2))\n",
    "print(round(mean([quicksum(coeff3[j][i]*alloc_ML[i] for i in range(V)).getValue() for j in range(num_samples)]), 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 ('venv2': virtualenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8 (default, Mar 25 2022, 11:15:52) \n[GCC 8.5.0 20210514 (Red Hat 8.5.0-10)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "5572670ece67f6053b5d3d6c38f26ac7cb6d3c6c25c5ff440df1e594edf47b46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
