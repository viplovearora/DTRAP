{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a45af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gurobipy import *\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from statistics import mean\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1de6a8ac",
   "metadata": {},
   "source": [
    "Read the data, the csv file can be obtained from https://www.pnas.org/doi/abs/10.1073/pnas.2016238117#supplementary-materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da24e3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv('pnas.2016238117.sd04.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9802db5f",
   "metadata": {},
   "source": [
    "Choose the year of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4529a51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2014\n",
    "dat_sub = dat[dat['year']==year]\n",
    "dat_sub = dat_sub.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d5cdc6",
   "metadata": {},
   "source": [
    "Define variables for the problem using the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989c3b9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "V = dat_sub.shape[0]\n",
    "Q = dat_sub['crew_size']\n",
    "Cq = np.log1p(dat_sub.iloc[:,20])\n",
    "gamma = 0.25\n",
    "k = (dat_sub['Prediction'] == 'Positive').sum() * gamma\n",
    "num_samples = 1000\n",
    "# define proportion of trafficking as a random variable\n",
    "s_mean = dat_sub['.pred_1']\n",
    "mar = .1\n",
    "s=np.minimum(np.maximum(np.random.triangular(left=s_mean-mar, mode=s_mean, right=s_mean+mar, size=(num_samples, len(s_mean))),0),1)\n",
    "\n",
    "S1 = [Q*(1-s[j]) for j in range(num_samples)]\n",
    "S2 = [Q*s[j] for j in range(num_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6668006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_rate(x):\n",
    "    xn = x/x.sum()\n",
    "    return xn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fdb728c1",
   "metadata": {},
   "source": [
    "Choose the base TPR and TNR rates (con_base) along with the bias scenario (ca) and compute the TPR and TNR rate for each vessel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf734c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_base=0.5\n",
    "ca = 'lpi'\n",
    "ytpr, ytnr = [], []\n",
    "con_set = dat_sub[['fishing_hours', 'average_voyage_duration_hours', 'average_loitering_duration_hours']]\n",
    "for h in range(V):\n",
    "    if ca == 'hpi':\n",
    "        ccon = error_rate(con_set.iloc[h,:])\n",
    "        if(ccon.min() < con_base and ccon.max() < con_base):\n",
    "            ytpr.append(con_base)\n",
    "            ytnr.append(con_base)\n",
    "        if(ccon.min() < con_base and ccon.max() > con_base):\n",
    "            ytpr.append(ccon.max())\n",
    "            ytnr.append(con_base)\n",
    "        if(ccon.min() > con_base and ccon.max() > con_base):\n",
    "            ytpr.append(ccon.max())\n",
    "            ytnr.append(ccon.min())\n",
    "    if ca == 'hni':\n",
    "        ccon = error_rate(con_set.iloc[h,:])\n",
    "        if(ccon.min() < con_base and ccon.max() < con_base):\n",
    "            ytpr.append(con_base)\n",
    "            ytnr.append(con_base)\n",
    "        if(ccon.min() < con_base and ccon.max() > con_base):\n",
    "            ytpr.append(con_base)\n",
    "            ytnr.append(ccon.max())\n",
    "        if(ccon.min() > con_base and ccon.max() > con_base):\n",
    "            ytpr.append(ccon.min())\n",
    "            ytnr.append(ccon.max())\n",
    "    if ca == 'hpln':\n",
    "        ccon = error_rate(con_set.iloc[h,:])\n",
    "        if(ccon.min() == 0):\n",
    "            ytpr.append(ccon.max())\n",
    "            ytnr.append(ccon.min() + float(np.random.uniform(0,.1,1)))\n",
    "        else:\n",
    "            ytpr.append(ccon.max())\n",
    "            ytnr.append(ccon.min())\n",
    "    if ca == 'lpi':\n",
    "        ccon = error_rate(con_set.iloc[h,:])\n",
    "        if(ccon.min() < con_base and ccon.max() < con_base):\n",
    "            ytpr.append(con_base)\n",
    "            ytnr.append(ccon.min())\n",
    "        if(ccon.min() < con_base and ccon.max() > con_base):\n",
    "            ytpr.append(con_base)\n",
    "            ytnr.append(ccon.min())\n",
    "        if(ccon.min() > con_base and ccon.max() > con_base):\n",
    "            ytpr.append(con_base)\n",
    "            ytnr.append(con_base)\n",
    "    if ca == 'lni':\n",
    "        ccon = error_rate(con_set.iloc[h,:])\n",
    "        if(ccon.min() < con_base and ccon.max() < con_base):\n",
    "            ytpr.append(ccon.min())\n",
    "            ytnr.append(con_base)\n",
    "        if(ccon.min() < con_base and ccon.max() > con_base):\n",
    "            ytpr.append(ccon.min())\n",
    "            ytnr.append(con_base)\n",
    "        if(ccon.min() > con_base and ccon.max() > con_base):\n",
    "            ytpr.append(con_base)\n",
    "            ytnr.append(con_base)\n",
    "    if ca == 'hnlp':\n",
    "        ccon = error_rate(con_set.iloc[h,:])\n",
    "        if(ccon.min() == 0):\n",
    "            ytnr.append(ccon.max())\n",
    "            ytpr.append(ccon.min() + float(np.random.uniform(0,.1,1)))\n",
    "        else:\n",
    "            ytnr.append(ccon.max())\n",
    "            ytpr.append(ccon.min())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8980d4cf",
   "metadata": {},
   "source": [
    "Compute coefficients for the optimization problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed69bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytpr, ytnr = np.array(ytpr), np.array(ytnr)\n",
    "coeff2 = [[a*b for a,b in zip(S2[j],ytpr)] for j in range(num_samples)]\n",
    "coeff3 = [[a*b for a,b in zip(S1[j],ytnr)] for j in range(num_samples)]\n",
    "coq = [S1[j]*(1-ytnr)+S2[j]*(1-ytpr) for j in range(num_samples)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "114473d9",
   "metadata": {},
   "source": [
    "Fix RHS for the opimization problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c361640",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 10000\n",
    "K = k\n",
    "L = 10000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e92deea",
   "metadata": {},
   "source": [
    "Formulate DTRAP-BIN for GFW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d458c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Model()\n",
    "m.ModelSense = 1  # minimize\n",
    "# Add variables\n",
    "x = m.addVars(V, vtype=GRB.BINARY, name='x')\n",
    "error = m.addVars(num_samples, obj=1.0/num_samples, name='error')\n",
    "# Set constraints\n",
    "m.addConstr(quicksum(Cq.iloc[i]*x[i] for i in range(V)) <= B, name=\"resources\")\n",
    "m.addConstrs((quicksum(coeff2[j][i]*x[i] for i in range(V)) >= K for j in range(num_samples)), name=\"HT\")\n",
    "m.addConstrs((quicksum(coeff3[j][i]*x[i] for i in range(V)) <= L for j in range(num_samples)), name=\"NHT\")\n",
    "m.addConstrs((error[j] == quicksum(coq[j].iloc[i]*x[i] for i in range(V)) for j in range(num_samples)), name='error')\n",
    "m.update()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77ec9f21",
   "metadata": {},
   "source": [
    "For HNI bias scenario, change the default optimality gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e8762c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ca == 'hni':\n",
    "    m.Params.MIPGap = .005"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10cb52e8",
   "metadata": {},
   "source": [
    "Solve the optimization problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d528256",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m.optimize()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4fba3de6",
   "metadata": {},
   "source": [
    "Compute values for the optimal allocation. These are used for creating Table 5 in the manuscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c122c75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_monitor = sum([v.X for k,v in x.items()])\n",
    "obj_vals = [v.X for k,v in error.items()]\n",
    "obj = np.mean(obj_vals)\n",
    "k_vals = [quicksum(coeff2[j][i]*x[i] for i in range(V)).getValue() for j in range(num_samples)]\n",
    "l_vals = [quicksum(coeff3[j][i]*x[i] for i in range(V)).getValue() for j in range(num_samples)]\n",
    "sol = [v.X for k,v in x.items()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c6f25c84",
   "metadata": {},
   "source": [
    "Save/load pickle object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6683c5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'sol_{ca}_{year}.pkl', 'wb') as f:\n",
    "    pickle.dump([num_monitor, obj_vals, k_vals, l_vals, sol], f)\n",
    "# with open(f'sol_{ca}_{year}.pkl', 'rb') as f:\n",
    "#     num_monitor, obj_vals, k_vals, l_vals, sol = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8443be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_monitor)\n",
    "print(round(mean(obj_vals), 2))\n",
    "print(round(sum([Cq.iloc[i]*sol[i] for i in range(V)]), 2))\n",
    "print(round(mean(k_vals), 2))\n",
    "print(round(mean(l_vals), 2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee032802",
   "metadata": {},
   "source": [
    "Get the allocations using the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c91eb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "alloc_ML = np.zeros(V)\n",
    "alloc_ML[np.argsort(s_mean)[-int(num_monitor):]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cad3057",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(mean(quicksum(coq[j]*alloc_ML).getValue() for j in range(num_samples)), 2))\n",
    "print(round(sum(Cq.iloc[i]*alloc_ML[i] for i in range(V)), 2))\n",
    "print(round(mean([quicksum(coeff2[j][i]*alloc_ML[i] for i in range(V)).getValue() for j in range(num_samples)]), 2))\n",
    "print(round(mean([quicksum(coeff3[j][i]*alloc_ML[i] for i in range(V)).getValue() for j in range(num_samples)]), 2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43c00c12",
   "metadata": {},
   "source": [
    "Plotting errors (Figure 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3957e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = np.mean(obj_vals)\n",
    "plt.rcParams['font.size'] = '12'\n",
    "plt.hist((obj_vals-obj)*100/obj, bins=30, alpha=0.75, label='DTRAP', density=True, color='#fde725')\n",
    "plt.hist(([quicksum(coq[j]*alloc_ML).getValue() for j in range(num_samples)]-obj)*100/obj, bins=30, alpha=0.75, label='ML model', density=True, color='#440154')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Errors', fontsize=14)\n",
    "plt.ylabel('Probability', fontsize=14)\n",
    "plt.savefig(f'{ca}_errors.pdf', bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28204a8d",
   "metadata": {},
   "source": [
    "Plotting trafficking cases detected (Figure 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045af34a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = '12'\n",
    "plt.hist((k_vals-np.mean(k_vals))*100/np.mean(k_vals), bins=30, alpha=0.75, label='DTRAP', density=True, color='#fde725')\n",
    "plt.hist(([quicksum(coeff2[j][i]*alloc_ML[i] for i in range(V)).getValue() for j in range(num_samples)]-np.mean(k_vals))*100/np.mean(k_vals), bins=30, alpha=0.75, label='ML model', density=True, color='#440154')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Trafficking', fontsize=14)\n",
    "plt.ylabel('Probability', fontsize=14)\n",
    "plt.savefig(f'{ca}_K.pdf', bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42cca524",
   "metadata": {},
   "source": [
    "Plotting non-trafficking cases monitored (Figure 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9631f7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = '12'\n",
    "plt.hist((l_vals-np.mean(l_vals))*100/np.mean(l_vals), bins=30, alpha=0.75, label='DTRAP', density=True, color='#fde725')\n",
    "plt.hist(([quicksum(coeff3[j][i]*alloc_ML[i] for i in range(V)).getValue() for j in range(num_samples)]-np.mean(l_vals))*100/np.mean(l_vals), bins=30, alpha=0.75, label='ML Model', density=True, color='#440154')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Non-trafficking', fontsize=14)\n",
    "plt.ylabel('Probability', fontsize=14)\n",
    "plt.savefig(f'{ca}_L.pdf', bbox_inches='tight', transparent=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 ('venv2': virtualenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "5572670ece67f6053b5d3d6c38f26ac7cb6d3c6c25c5ff440df1e594edf47b46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
